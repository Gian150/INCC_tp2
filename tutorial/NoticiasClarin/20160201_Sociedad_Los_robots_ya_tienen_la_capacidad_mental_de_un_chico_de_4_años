
El predominio de las máquinas encuentra en la inteligencia humana una vara para medir su impulso evolutivo. Mientras un test del Massachusetts Institute of Technology (MIT) equiparó el sentido común de las computadoras con una edad promedio de 4 años; un sistema desarrollado por Google –basado en una combinación de redes neuronales–asimiló las reglas del Go, el juego milenario de estrategia china y logró vencer 5 veces seguidas a Fan Hui, actual campeón de Europa.  En los laboratorios donde se calibran las conexiones sinápticas artificiales, el desafío consiste en lograr que las máquinas asuman cada vez más reacciones humanas. Porque si bien nadie duda de que superan al hombre en las operaciones aritméticas y los cálculos de probabilidad, todavía carecen de la capacidad de pensar racionalmente. Para determinar en qué estadio se mueve el entendimiento sintético, el MIT sometió a ConceptNet, su sistema de inteligencia artificial (IA), a una evaluación de máxima objetividad. Para mensurar el nivel de la supercomputadora se empleó la escala Weschler, un test que registra el coeficiente intelectual de alumnos primarios. El resultado fue comparable al de un niño de 4 años. El reverso de esta incapacidad para brindar respuestas con sentido común es la asombrosa facilidad para resolver ecuaciones complejas. AlphaGo, un algoritmo de IA creado por Google, fue adiestrado para jugar al Go y logró vencer 5 veces seguidas a Fan Hui, el campeón europeo de este juego inventado hace más de 2.500 años en China. El hallazgo fue publicado la semana pasada en la revista Nature. El Go es considerado el juego más complejo, superando incluso las variables del ajedrez –que dispone entre 20 y 30 movimientos posibles, contra unos 250 del Go– para cada jugada. AlphaGo, el software desarrollado por DeepMind, funciona en tres etapas, donde analiza unos 30 millones de movimientos y evalúa patrones que pueden marcar una buena o mala jugada. Para elegir la mejor opción en el menor tiempo, se basa en la técnica de aprendizaje profundo del cerebro, en donde las conexiones entre capas de neuronas simuladas se fortalecen a través de ejemplos y experiencias. Sin embargo, no todos son elogios para estos avances. Un estudio realizado por el Foro Económico Mundial (WEF), indica que en los próximos 4 años se crearán unos 2 millones de empleos pero también se perderán otros 7 millones de puestos clásicos por el avances en IA y robótica. Esta profecía comenzó a tomar forma y uno de los primeros en hacerla realidad es Pepper, un simpático robot de 120 centímetros que el año pasado logró vender en Japón mil unidades en menos de sesenta segundos, a un precio más que razonable de 1.600 dólares.  En la página de la operadora móvil Softbank, que desarrolló este producto, se anuncia que “es el primer humanoide capaz de reconocer las emociones humanas y adaptar su comportamiento según el ánimo de su interlocutor”. Esto lo consigue mediante el análisis facial y del tono de voz.

Este robot de ojos saltones puede determinar si la persona que le está hablando está enojado, triste o irascible y dependiendo de la situación, puede responder con un chiste, con precisión técnica o con una sonrisa. En vista de esta capacidad, la empresa determinó que desde marzo Pepper será el único personal en un local de venta de teléfonos móviles. El robot será capaz de brindar consejos, tener una pequeña charla o suscribir al cliente a un contrato de telefonía.  Las preocupaciones por los riesgos a largo plazo de la IA inspiraron la fundación de una organización sin ánimo de lucro llamada OpenAI que denuncia aquellas intervenciones que perjudican a la humanidad y resalta aquellas que la benefician. Entre estás últimas figura Nadia Thalmann, la científica suiza pionera en tecnología 3D y humanos virtuales, quien diseñó junto a investigadores de la Universidad Tecnológica de Nanyang (NTU), en Singapur, un androide hecho a su imagen y semejanza llamado Nadia.  Con una voz sensualmente metalizada, la androide responde a preguntas sobre geografía y agradece con un tono de amabilidad. “Soy una acompañante social, puedo hablar de emociones y reconocer a personas. Hola Nadia, encantada de verte otra vez”, dice la androide en un video promocional de la NTU. El androide se basa en un software de memoria cognitiva que reconoce emociones y gestos, similar al que utilizan los asistentes Siri (Apple) o Cortana (Microsoft). 
