El jueves pasado un cohete que cargaba un satélite de Facebook explotó durante una prueba de lanzamiento. Una explosión igual de resonante pero más silenciosa se produjo también esta semana en el corazón de las oficinas de Facebook, por la difusión de tres noticias que resultaron ser falsas. El viernes pasado, Facebook había despedido a los integrantes del equipo de la sección “Trending”, encargados de editar esos contenidos, y los había reemplazado por un proceso automático. Pero la decisión tuvo consecuencias poco felices, y las fallas llegaron mucho antes de lo esperado. Uno de los errores que cometió Facebook fue la difusión de una noticia relacionada con contenido del programa humorístico Saturday Night Live: el error fue no detectar la ironía. Pero esto es apenas el último eslabón de una discusión que viene desde mayo, cuando un medio digital había criticado el modo por el cual Facebook ordenaba y distribuía su contenido. Incluso una nota del sitio Gizmodo denunció que esa edición era arbitraria y que se habían censurado temas por una decisión política, cuando Facebook se autoproclama como un mero distribuidor, lo más neutral posible. El escándalo también estuvo relacionado con la denuncia de los ex empleados que había contratado la compañía. Incluso una de ellas denunció que había sido “la experiencia más tóxica de su vida”. Denunció que la discriminaban porque era mujer y que el trato era muy hostil y exigente para todo el equipo. En los “Trending” de Facebook (una opción aún no disponible para los países hispanoparlantes) se muestran los temas más resonantes del momento, también relacionados con los intereses y la ubicación geográfica del usuario. Hasta la semana pasada, la sección era “curada” por un equipo de 18 personas. O, en todo caso, era una tarea mixta: el algoritmo hacía el trabajo de selección más duro, pero la edición final y un pequeño resumen de los temas era redacatado por un equipo humano. Pero para “mejorar” el proceso y sacarle la subjetividad de los humanos, Facebook decidió despedirlos y confiarle toda la tarea a un algoritmo, que en pocos días falló de manera grosera.   En esta discusión no se trata simplemente de un reemplazo de la máquina por el hombre; el algoritmo también es gestionado por humanos, recibe “órdenes” y actúa en consecuencia. En todo caso, el cambio es de paradigma: lo que desaparece son los periodistas, los que se suman a la tarea son ingenieros y programadores. Se trata también de un nuevo capítulo en una discusión cada vez más presente en el mercado de la comunicación: el de la distribución y generación de los contenidos. Mark Zuckerberg, fundador de Facebook, siempre remarca que la red social se encarga únicamente de la distribución del contenido y lo remarcó esta semana en Roma, durante sus encuentros con el Papa Francisco: “Somos una compañía de tecnología, no de medios. No producimos contenido”. Pero para varios especialistas es una idea equivocada. “No importa lo que diga Zuckerberg sobre si Facebook es una compañía de medios o no. Está teniendo atribuciones propias de las compañías de medios”, dice Emily Bell, directora de la escuela de Periodismo Digital de la Universidad de Columbia. Aún en la creación de un algoritmo hay una decisión editorial. Por ejemplo, que la orden tenga que ver con distribuir contenido con más fotos que texto. Eso supone una cierta edición, un modo de ver el mundo. “Los algoritmos no son más objetivos que los seres humanos. Las personas que los diseñan les dan indicaciones para que elijan eso que finalmente terminan eligiendo”, dice Grzegorz Piechota, investigador de la universidad de Harvard A pesar de las acusaciones, Facebook sigue manteniendo su idea de neutralidad: ellos solo distribuyen el contenido y no tienen influencia en la selección. Remarcaron que tienen una lista de 1000 medios de confiaza para levantar la información y que en Estados Unidos, por ejemplo, para que una noticia entrara en el “Trending” tenía que estar publicada en al menos cinco de los 10 medios más populares. Ante el error, dijeron que van a trabajar para mejorar ese algoritmo, pero que no volverán a contratar humanos para esa curaduría. Lo mismo dijo Zuckerberg cuando vio su cohete estallar: “Vamos a seguir intentando”. 