
 Varios grupos de activistas, entre ellos la premio Nobel de la Paz de 1997, Jody Williams, pidieron a las Naciones Unidas que inicien los trámites necesarios para legislar sobre los conocidos como "robots asesinos", como se llama a las máquinas capaces de matar sin la intervención humana.  Quieren que el reclamo sea tenido en cuenta durante l próximo viernes 14 de abril, cuando se debata en las Naciones Unidas en Ginebra la creación de un marco legislativo para estos sistemas autónomos letales, dentro de la convención de Ciertas Armas Convencionales (CCW).  Mirá también: Los cerebros de la Inteligencia Artificial: “Debemos prohibir a los robots asesinos”  Pese a que casi una treintena de países se oponen abiertamente al desarrollo de armamento autónomo y abogan por crear un marco legal que defina cómo y cuándo deben usarse, hay aún países como los Estados Unidos, Rusia o China que no propician que se regule.  Según explicó el director del Comité Internacional para el control de robots-armas, Noel Sharkey, por ahora ningún país bloquea la idea de crear el marco legal, pero al mismo tiempo no se avanza en el proceso.   Según Sharkey, cada dilación permite que tanto los países como las empresas sigan desarrollando este tipo de armas sin ningún control internacional.  El peligro reside en que ya hay países que cuentan con ciertas tecnologías previas a los sistemas autónomos totales. Piden postergaciones,  y "pueden repetir lo mismo durante cien años", alertó Sharley.   La definición de lo que es un arma autónoma es uno de los obstáculos principales en el debate mundial.   "Ni siquiera hemos sido capaces de definir lo que quiere decir 'control humano significativo'... aunque algunos tengamos muy claro qué significa", señaló Williams.   Asimismo, los activistas explicaron que en estos casos es difícil acotar la definición de arma letal, ya que, según Sharkey, "se puede matar de muchas formas" y con armas que a priori no serían letales, como los taser (pistolas eléctricas) o las pelotas de goma.  Además, los expertos mostraron su preocupación por quién asumiría la responsabilidad por estas máquinas, es decir si hubiera errores fatales, qué persona o instancia pagaría por ello.  Mirá también: Los robots ya tienen la capacidad mental de un chico de 4 años  "¿Quién respondería, el programador? ¿La empresa fabricante? ¿El dueño de la máquina...? No se puede encarcelar a un robot, y aunque lo hiciéramos, daría igual. Una máquina no debería ser capaz de matar a una persona por sí sola, no hay más que decir", concluyó Williams.
